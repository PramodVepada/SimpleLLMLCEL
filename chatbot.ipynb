{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001F43D1AE9E0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001F43D1AD720>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model='gemma2-9b-it',api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Pramod,\\n\\nIt's nice to meet you!  As a Senior Machine Learning Engineer, what are you currently working on that excites you?  \\n\\nI'm always eager to learn more about the cutting edge of ML.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 24, 'total_tokens': 75, 'completion_time': 0.092727273, 'prompt_time': 0.00015086, 'queue_time': 0.015438627000000002, 'total_time': 0.092878133}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-df9b2df6-9167-462f-bae7-58fd9b470fa2-0', usage_metadata={'input_tokens': 24, 'output_tokens': 51, 'total_tokens': 75})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "messages = [HumanMessage(content=\"Hi, My name is Pramod and I am a Senior Machine Learning Engineer\")]\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Pramod, and that you are a Senior Machine Learning Engineer who enjoys traditional machine learning but is currently working on LLM models. \\n\\nIs there anything else you'd like me to know about you? üòä  I'm always learning!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 119, 'total_tokens': 178, 'completion_time': 0.107272727, 'prompt_time': 0.003751098, 'queue_time': 0.00916453, 'total_time': 0.111023825}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-5988d91a-f97f-4630-87e9-69df70b133d6-0', usage_metadata={'input_tokens': 119, 'output_tokens': 59, 'total_tokens': 178})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "message = [\n",
    "    HumanMessage(content=\"Hi, My name is Pramod and I am a Senior Machine Learning Engineer\"),\n",
    "    AIMessage(content=\"Hi Pramod, it's nice to meet you!\\n\\nAs a Senior Machine Learning Engineer, I imagine you have a lot of experience and expertise. \\n\\nWhat kind of projects are you working on these days?\"),\n",
    "    HumanMessage(content=\"I am enjoy traditional Machine Learning but nowadays I am working on LLM Models\"),\n",
    "    AIMessage(content=\"That is great!!\"),\n",
    "    HumanMessage(content=\"What is my name and what do you know about me?\")\n",
    "]\n",
    "\n",
    "model.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and no access to personal information about you. So, I don't know your name or anything else about you. If you'd like to tell me your name, I'd be happy to know!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 21, 'total_tokens': 78, 'completion_time': 0.103636364, 'prompt_time': 0.00014439, 'queue_time': 0.013567128000000001, 'total_time': 0.103780754}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-59bfc7f0-1031-474f-98a0-43e4dbf1a990-0', usage_metadata={'input_tokens': 21, 'output_tokens': 57, 'total_tokens': 78})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"What is my name and what do you know about me?\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Message History\n",
    "\n",
    "The MessageHistory class in LangChain is designed to keep track of the conversation history between a user and a language model. It stores each user and model message, creating a context that is crucial for generating responses that consider the conversation‚Äôs flow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "#when multiple users are talking with the llm, how will we make sure that each session is different\n",
    "store = {}\n",
    "\n",
    "def get_message_history(session_id:str)-> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_message_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'configurable':{'session_id':'chat1'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is Pramod and I am senior Machine Learning Engineer\")],config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Pramod! It's great to meet you.  \\n\\nBeing a senior Machine Learning Engineer, I'm sure you've got a wealth of knowledge and experience. What are you currently working on that you find most exciting?  Do you have any particular areas of ML that you specialize in? \\n\\nI'm always eager to learn more about the cutting edge of the field!\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Pramod. üòä  I remember from our introduction! \\n\\nIs there anything else I can help you with?  Perhaps you'd like to discuss some machine learning concepts or projects?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 200, 'total_tokens': 244, 'completion_time': 0.08, 'prompt_time': 0.005838002, 'queue_time': 0.007503296999999999, 'total_time': 0.085838002}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-97d4ec62-cf46-4f1f-bc59-849ac7668005-0', usage_metadata={'input_tokens': 200, 'output_tokens': 44, 'total_tokens': 244})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name.\\n\\nIf you'd like to tell me your name, I'd be happy to use it!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 14, 'total_tokens': 56, 'completion_time': 0.076363636, 'prompt_time': 7.842e-05, 'queue_time': 0.013283358, 'total_time': 0.076442056}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-064a53b5-1510-43ed-958c-8475d7e41b7f-0', usage_metadata={'input_tokens': 14, 'output_tokens': 42, 'total_tokens': 56})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'configurable':{'session_id':'chat2'}}\n",
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"Answers the questions asked by user to the best of your ability\"),\n",
    "    MessagesPlaceholder(variable_name=\"keys\")#instead of keys you can use any string.\n",
    "    \n",
    "])\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Pramod! It's nice to meet you.  \\n\\nAs a large language model, I'm ready to answer your questions to the best of my ability. What can I help you with today?  \\n\\nDo you have any specific topics in machine learning you'd like to discuss, or are you just curious about my capabilities?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 35, 'total_tokens': 108, 'completion_time': 0.132727273, 'prompt_time': 0.001642754, 'queue_time': 0.011499484, 'total_time': 0.134370027}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-34093e85-7a67-4a45-9186-5c93a41c7976-0', usage_metadata={'input_tokens': 35, 'output_tokens': 73, 'total_tokens': 108})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"keys\":[HumanMessage(content=\"Hello, My name is Pramod, I am a Machine Learning Engineer\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain,get_message_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "res = with_message_history.invoke([\n",
    "    HumanMessage(content=\"Hi my name is Pramod and I am an ML Engineer\")],config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Pramod! It's nice to meet you.\\n\\nWhat can I do for you today? I'm ready to answer your questions to the best of my ability.  Since you're an ML Engineer, perhaps you have some interesting questions about machine learning or AI?  \\n\\nLet me know how I can help! üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 33, 'total_tokens': 106, 'completion_time': 0.132727273, 'prompt_time': 0.000313669, 'queue_time': 0.013146848999999999, 'total_time': 0.133040942}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-0c502f7d-b0cf-4a2b-a4ff-09d603109ed0-0', usage_metadata={'input_tokens': 33, 'output_tokens': 73, 'total_tokens': 106})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding more complexity\n",
    "prompt2 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"Answers the questions asked by user to the best of your ability in {language}\"),\n",
    "    MessagesPlaceholder(variable_name=\"keys\")#instead of keys you can use any string.\n",
    "    \n",
    "])\n",
    "chain1 = prompt2|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§™‡•ç‡§∞‡§Æ‡•ã‡§¶ ‡§ú‡•Ä! \\n\\n‡§Æ‡•Å‡§ù‡•á ‡§Ü‡§™‡§ï‡•á ‡§®‡§æ‡§Æ ‡§∏‡•á ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•Å‡§à‡•§ ‡§Ü‡§™ ‡§è‡§ï ML ‡§á‡§Ç‡§ú‡•Ä‡§®‡§ø‡§Ø‡§∞ ‡§π‡•à‡§Ç?  ‡§ï‡•ç‡§Ø‡§æ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•ã‡§à ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å?  \\n\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = chain1.invoke({\"keys\":[HumanMessage(content=\"Hi my name is Pramod and I am an ML engineer\")],\"language\":\"Hindi\"})\n",
    "r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain1,get_message_history,input_messages_key=\"keys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "res = with_message_history.invoke({\"keys\":[\n",
    "    HumanMessage(content=\"Hi my name is Pramod and I am an ML Engineer\")],\"language\":\"Hindi\"},config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡§®‡§Æ‡§∏‡•ç‡§§‡•á Pramod!  ‡§Æ‡•Å‡§ù‡•á ‡§Ü‡§™‡§∏‡•á ‡§Æ‡§ø‡§≤‡§ï‡§∞ ‡§¨‡§π‡•Å‡§§ ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à‡•§  \\n\\n‡§Ü‡§™ ‡§è‡§ï ML ‡§á‡§Ç‡§ú‡•Ä‡§®‡§ø‡§Ø‡§∞ ‡§π‡•à‡§Ç, ‡§§‡•ã ‡§Ü‡§™ ‡§á‡§® ‡§¶‡§ø‡§®‡•ã‡§Ç ‡§ï‡§ø‡§∏ ‡§§‡§∞‡§π ‡§ï‡•á ‡§™‡•ç‡§∞‡•ã‡§ú‡•á‡§ï‡•ç‡§ü‡•ç‡§∏ ‡§™‡§∞ ‡§ï‡§æ‡§Æ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç? \\n\\n‡§Æ‡•à‡§Ç ‡§Æ‡§∂‡•Ä‡§® ‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó ‡§ï‡•á ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞ ‡§Æ‡•á‡§Ç ‡§π‡•ã ‡§∞‡§π‡•á ‡§∞‡•ã‡§Æ‡§æ‡§Ç‡§ö‡§ï ‡§ï‡§æ‡§Æ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§Ö‡§ß‡§ø‡§ï ‡§ú‡§æ‡§®‡§®‡•á ‡§Æ‡•á‡§Ç ‡§π‡§Æ‡•á‡§∂‡§æ ‡§∞‡•Å‡§ö‡§ø ‡§∞‡§ñ‡§§‡§æ ‡§π‡•Ç‡§Ç‡•§ \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 92, 'prompt_tokens': 111, 'total_tokens': 203, 'completion_time': 0.167272727, 'prompt_time': 0.003582389, 'queue_time': 0.01007071, 'total_time': 0.170855116}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-15f91fab-a27f-44e3-ac34-afa2ca261c94-0', usage_metadata={'input_tokens': 111, 'output_tokens': 92, 'total_tokens': 203})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = with_message_history.invoke({\"keys\":[\n",
    "    HumanMessage(content=\"what do you know about me?\")],\"language\":\"Hindi\"},config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡§Æ‡•Å‡§ù‡•á ‡§Ö‡§≠‡•Ä ‡§§‡§ï ‡§Ü‡§™‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§¨‡§π‡•Å‡§§ ‡§ï‡§Æ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§π‡•à‡•§  \\n\\n‡§Æ‡•à‡§Ç ‡§ú‡§æ‡§®‡§§‡§æ ‡§π‡•Ç‡§Å ‡§ï‡§ø ‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ Pramod ‡§π‡•à ‡§î‡§∞ ‡§Ü‡§™ ‡§è‡§ï ML Engineer ‡§π‡•à‡§Ç‡•§   ‡§Ü‡§™‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§î‡§∞ ‡§ú‡§æ‡§®‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ï‡•Å‡§õ ‡§î‡§∞ ‡§¨‡§§‡§æ‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç‡§ó‡•á?  \\n\\n‡§ú‡•à‡§∏‡•á, ‡§Ü‡§™ ‡§ï‡§ø‡§∏ ‡§§‡§∞‡§π ‡§ï‡•á ML ‡§™‡•ç‡§∞‡•ã‡§ú‡•á‡§ï‡•ç‡§ü‡•ç‡§∏ ‡§Æ‡•á‡§Ç ‡§∞‡•Å‡§ö‡§ø ‡§∞‡§ñ‡§§‡•á ‡§π‡•à‡§Ç? ‡§Ü‡§™ ‡§ï‡§π‡§æ‡§Å ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç?   \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 91, 'prompt_tokens': 218, 'total_tokens': 309, 'completion_time': 0.165454545, 'prompt_time': 0.006771359, 'queue_time': 0.006714258999999999, 'total_time': 0.172225904}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-239685ef-09ee-42af-85da-e3371524ca49-0', usage_metadata={'input_tokens': 218, 'output_tokens': 91, 'total_tokens': 309})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
